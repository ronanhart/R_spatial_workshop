[["index.html", "R Spatial Workshop Chapter 1 Welcome to the Ecology Centers Workshop on R Spatial! Why GIS in R? Prerequisites, Packages, and Preparation", " R Spatial Workshop Ronan Hart 2022-04-06 Chapter 1 Welcome to the Ecology Centers Workshop on R Spatial! In this workshop we will cover: GIS Basics Vectors &amp; Rasters and how to manipulate them in R Basic GIS functions (Briefly) where to obtain environmental GIS data We will NOT be covering how to make a nice-looking map (for figures, presentations, etc.) That will be covered in the next workshop, so be sure to keep an eye out for that if you want to learn how to make maps in R! Goals of this workshop: Reiterate the basics of GIS Teach you the processes that you might have learned in ArcGIS or other GIS software that you can code yourself in R Why GIS in R? You may be asking why you even need to learn how to code spatial processes in R, especially if you already know how to use ArcGIS. (Well, maybe youre not actually asking that question if youre taking this class.) But here are a few reasons why: Free you most often need to pay companies to use their GIS software (or be a student to use a universitys license). What happens when youre no longer a student nor hired by a company/organization that already has a license? Reproducible Some journals require you to publish your code alongside your manuscript If you are collaborating on a project, you can Open-Source company-owned software is often hidden behind a black box so you might not be 100% certain what a function or tool is doing. Functions in R are completely open to the public so you can be certain that a function is doing what you think its doing Customizable You can write your code to suit your specific problem and answer your specific questions You can write custom functions and loops so that you can repeat processes on multiple features and rasters without having to copy and paste code Reproducibility and customization are not unique to R but rather an advantage to using code for GIS in general. In a few weeks there will be a workshop on coding in python for GIS tools, which is just as useful (especially because you can use the package arcpy in python to code directly to ArcGIS), so I also recommend taking that workshop if youre interested. Not to say that programs such as ArcGIS should never be used. On the contrary, since it was the way I first learned GIS, I will sometimes return to it to make a map on the fly or quickly visualize and double-check a polygon or raster. All programs have their pros and cons, and this workshop is to simply add another tool in your spatial analysis toolbox. Prerequisites, Packages, and Preparation Before we begin, please be sure you have done the follow preparations: Make sure you have a recent version of R and RStudio installed to check your version of R, type R.version in the console. version.string will have the version number and its release date. The most recent version (as of 2022-03-30) is 4.1.3 (released on 2022-03-10). Version 4.1.2 is perfectly fine for this workshop. to check your version of RStudio, Go to Help (in the toolbar at the top) &gt; Check for Updates. RStudio 2022.02.1+461 is the most recent version. Version 2021.09.2+382 is perfectly fine for this workshop. Install (if needed) and load the following packages: install.packages(&quot;raster&quot;) install.packages(&quot;rgdal&quot;) install.packages(&quot;rgeos&quot;) install.packages(&quot;sf&quot;) install.packages(&quot;sp&quot;) install.packages(&quot;tidyverse&quot;) library(raster) library(rgdal) library(rgeos) library(sf) library(sp) library(tidyverse) (Optional but recommended) Create a new RStudio project. This will make it easier to access files within your code and keep everything organized. Heres a guide on how to do that After taking care of that, lets get started! "],["gis-basics.html", "Chapter 2 GIS basics 2.1 Datums, Projections, and Coordinate Systems 2.2 Spatial Data 2.3 Vectors vs Rasters: pros &amp; cons", " Chapter 2 GIS basics I apologize if youve taken a GIS course or two and are already familiar with these concepts. I want to make sure were all on the same page and that we all know how these concepts work in R. 2.1 Datums, Projections, and Coordinate Systems Datums The Earth is a spheroid (also called an ellipsoid). Because of variations in elevation across the world, the Earths surface is irregular. Figure 2.1: Conceptual representation of the irregular, spheroid shape of the Earth A datum (also called a geographic coordinate system) is a reference surface that best fits the mean surface area of an area of interest. There is a global datum to represent the general surface of the Earth as a whole  World Geodetic System of 1984 i.e. WGS84. Figure 2.2: Red ellipse represents the smooth, general surface of the Earth (i.e. a global datum) However, because the Earths surface is irregular and the global datum might not reflect specific areas and variations in elevations, there are also local datums. A common local datum (for North America at least) is the North America Datum of 1983 (NAD83) . Figure 2.3: Yellow line indicates a specific area, purple ellipse represents the smooth, general surface of the Earth at this location. Note that this local datum would not be a best fit in other places on the Earth The datum you choose to work with is up to you and where your study takes place. It is very important to know what datum youre working with and that you remain consistent because coordinates of a location from one datum are likely different than the same location from a different datum. For example, if we look at the coordinates for Bellingham, Washington: Datum Longitude Latitude NAD 1983 -122.46818353793 48.7438798543649 WGS 1984 -122.46818353793 48.7438798534299 While the differences between NAD83 and WGS84 are not huge, these differences could impact any spatial analysis you perform. Also note that you would need to choose a different local datum if youre working outside of North America. Projections While a datum references the position of an object in geographic space on a 3D surface, a projection (also called a projected coordinate system) represents that 3D surface onto a 2D plane. Figure 2.4: Conceptual demonstration of map projections This is important to know when plotting a map for a figure, as your chosen projection will change the visualization and shape of your maps features. But more importantly for spatial analysis, a projection is needed when you need values such as length, area, or distance. Map projections are never 100% accurate, so every 2D map will have show some distortion. Different projections preserve different properties of the world, such as the relative shape of features, area, distance, or angle. For that reason, its important to pick a projection that would provide the highest accuracy for your region and the analysis youre running. A common projection to use is the Universal Transverse Mercator or UTM. Figure 2.5: UTM around the globe Figure 2.6: UTM for the US If your study region is in Utah, for example, you would use UTM Zone 12 N (or UTM 12N). Note that while you will always have a datum, you do not necessarily need to ALWAYS use a projection. As for anything, it depends on your analysis and your system. Coordinate Reference System A coordinate reference system or CRS is simply the combination of the datum (geographic coordinate system) and the projection (projected coordinate system). For example, if you are working with the 1984 World Geodetic System that is projected to UTM Zone 12N, your CRS would be WGS84 UTM12N. If you are working with the 1983 North America Datum that is projected to UTM Zone 14N, your CRS would be NAD83 UTM14N. And so on. These different combinations of CRS all have their own EPSG code. (These codes were orginally created by the European Petroleum Survey Group, which is where the acronym comes from). For example, the EPSG code for WGS84 latitude/longitude (i.e. no projection) is 4326, the EPSG code for NAD83 UTM12N is 26912, and so on. These codes can easily be found on the Spatial Reference Website (or google if you forget what the website is). 2.2 Spatial Data Vectors Vector data are shapes with a geometry that can represent real world features. These geometries which can be made up of one or more vertices and paths. A vertex describes a position in space with x and y coordinates. A feature with one vertex would be a point, a feature with two or more vertices where the first and last vertices dont connect would be a polyline, and a feature with at least three vertices and the first and last vertices connect (an enclosed area) would be polygon. Points animal positional locations study site coordinates tree locations Lines roads fences boundaries rivers Areas (or polygons) bodies of water parks USFS land study plots area burned by a fire Example with random vertices: Figure 2.7: Figure demonstrating points (red), polylines (black), and polygon (blue) Or an example with Utah features: Figure 2.8: Figure demonstrating points (major Utah cities), polylines (major Utah highways), and polygons (shape of Utah boundary) Vector features have attributes, which can be text or numerical information that describe the features. These attributes are stored in a data frame. ## name state pop lat long capital ## 1 Bountiful UT UT 41622 40.88 -111.87 0 ## 2 Layton UT UT 63096 41.08 -111.95 0 ## 3 Logan UT UT 45262 41.74 -111.84 0 ## 4 Murray UT UT 56848 40.65 -111.89 0 ## 5 Ogden UT UT 78572 41.23 -111.97 0 ## 6 Orem UT UT 94758 40.30 -111.70 0 ## 7 Provo UT UT 105832 40.25 -111.64 0 ## 8 Saint George UT UT 63952 37.08 -113.58 0 ## 9 Salt Lake City UT UT 177318 40.78 -111.93 1 ## 10 Sandy UT UT 89698 40.57 -111.85 0 ## 11 Taylorsville UT UT 58200 40.66 -111.94 0 ## 12 West Jordan UT UT 105629 40.60 -111.99 0 ## 13 West Valley City UT UT 113989 40.69 -112.01 0 The important information you need from your vector data are: the geometry type (if its a point, line, or polygon) the coordinate reference system the bounding box (the min/max points in x and y geographical space) Rasters Rasters are data represented by pixels (or cells) where each pixel has its own value. These cell values can be continuous (e.g. elevation, temperature, snow depth) or discrete (e.g. land cover, habitat type, presence/absence). Figure 2.9: Map showing a raster with continuous values (elevation) Figure 2.10: Map showing a raster with discrete values (land cover) Raster data can have more than one band (where each band is a single raster). These raster layers can stack together to create a Raster Stack or a Raster Brick (the differences between these two are minor and we will go into more depth later). For example, satellite imagery is a stack of 3 rasters, each containing continuous values indicating levels of Red, Green, and Blue. These 3 bands come together to make a true-color image. The important information you need from your raster data are the coordinate reference system the extent (the min/max points in x and y geographical space) the cell resolution (the width and height of each cell) The cell resolution basically means how pixel-y the raster is. A finer resolution (meaning the cell size is smaller) will have more detail than a coarser resolution (meaning the cell size is larger). For example, compare a raster with a pretty fine resolution (in this case 30m X 30m, meaning that each cells is 30m wide and 30m high) Figure 2.11: Map showing a raster with fine resolution (30m X 30m) Compared to the same raster but with a coarser resolution (in this case 300 m X 300 m) Figure 2.12: Map showing a raster with coarse resolution (300 m X 300 m) Wouldnt we always want to work with finer resolutions? If rasters with finer resolutions have more detail (and thus are more accurate to whats actually on the landscape) than one with a coarser resolution, why would we ever work with a raster with coarse resolution? I can think of 2 reasons why: Sometimes you simply cant obtain that data in a finer resolution. For example, MODIS offers NDVI rasters every 16 days, but the finest resolution is 250m. The finer the resolution, the more cells there are, and so the time to do any sort of computation or analysis on these cells increases. As for everything, it depends on your analysis and your system. 2.3 Vectors vs Rasters: pros &amp; cons Advantages of Vectors Because vectors are just vertices and paths (rather than upwards of thousands of grid cells), it takes less time to load, save, or perform any computation or analysis on a vector compared to a raster. (They also take up less disk space on your hard drive) For the same reason, they can often be more geographically accurate. A vectors vertex is located at a single lat/long coordinate compared to a raster pixel at the same location but covers 250mX250m. Disadvantages of Vectors It is difficult to store and display continuous data in vectors. (It can be done, but the data typically would need to be binned) Vectors are best used to represent features of the landscape, rather than the landscape itself. Advantages of Rasters Rasters are best for satellite and other remotely sensed data. As the point above mentioned, they are great for representing the landscape itself. It is relatively easy and intuitive to perform any quantitative analysis with rasters. When raster cells are stacked (see figure below), it is pretty straightforward to perform any focal statistics or cell algebra. Figure 2.13: A stack of rasters, showing how each cell would correspond to the ones on top and below Disadvantages of Rasters Depending on the resolution, they can look pixellated and not visually appealing. For analysis, this would affect computation time and disk space. Raster cells can only contain one value (compared to vectors, which can have an entire attribute table). If you want cells to contain more than one value, you would need a stack of rasters, which takes up disk space and computation power. Now that we know about coordinate reference systems, vectors, and rasters, lets learn how to deal with all of these in R! "],["spatial-data-in-r.html", "Chapter 3 Spatial Data in R 3.1 Vectors 3.2 Rasters", " Chapter 3 Spatial Data in R 3.1 Vectors The primary packages that deal with these features are sf and sp sf means simple feature while sp is short for spatial. There are pros and cons to both (for example, a lot of other packages depend on sp, sf works well in tidyverse, etc.). However, in my opinion, there is no reason that you cant use both in the same code, if needed. This website goes into more detail about these packages and the specifics about objects from these packages. 3.1.1 Loading vector data from a spreadsheet You will often have a spreadsheet of data that have two columns of latitude and longitude (and potentially other columns for the attributes of these features). sites &lt;- read.csv(&quot;Data/Examples/Sites.csv&quot;) head(sites) ## Site Latitude Longitude ## 1 1 37.84203 -110.8090 ## 2 2 39.04723 -111.3390 ## 3 3 38.04543 -109.2163 ## 4 4 39.71574 -113.1987 ## 5 5 41.50760 -111.5509 ## 6 6 38.75022 -111.5154 class(sites) ## [1] &quot;data.frame&quot; How can we convert this data table into a spatial object? With sf Well use the function st_as_sf() to convert an object of another class to an sf object. As with any function, you can always type ?st_as_sf in the console to remind yourself what the function does and what arguments you need to add. In this case, the non-optional arguments are x (the object we want to convert, in this case our sites data frame) and coords (the columns in the data frame that have the coordinate data). The argument crs is optional but we should add it so that our spatial object has a coordinate reference system. Because our coordinates are lat/long, we should tell st_as_sf that our crs is WGS84 lat/long (Remember that the EPSG code for WGS84 lat/long is 4326). Note: Even if youre working in a different geographic or projection coordinate system, it is ALWAYS good practice to load in lat/long coordinates as WGS84 lat/long and then later projecting the object, instead of right away giving it a projected coordinate system. This is because GPS coordinates work with a global datum (being a global positioning system), and you might have inaccurate positions if you load it in with another datum or projection. sites_sf &lt;- st_as_sf(sites, coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) head(sites_sf) ## Simple feature collection with 6 features and 1 field ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: -113.1987 ymin: 37.84203 xmax: -109.2163 ymax: 41.5076 ## Geodetic CRS: WGS 84 ## Site geometry ## 1 1 POINT (-110.809 37.84203) ## 2 2 POINT (-111.339 39.04723) ## 3 3 POINT (-109.2163 38.04543) ## 4 4 POINT (-113.1987 39.71574) ## 5 5 POINT (-111.5509 41.5076) ## 6 6 POINT (-111.5154 38.75022) Now when we look at the head of sites_sf it also prints out some information about this spatial object: it is a simple feature, it is a POINT object, the min/max coordinates (the bounding box), and the CRS. Note that the Longitude and Latitude columns turned into a geometry column. We can also check this information with separate functions: st_bbox and st_crs st_bbox(sites_sf) ## xmin ymin xmax ymax ## -113.50131 37.55458 -109.21630 41.50760 st_crs(sites_sf) ## Coordinate Reference System: ## User input: EPSG:4326 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;geodetic latitude (Lat)&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;geodetic longitude (Lon)&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## USAGE[ ## SCOPE[&quot;Horizontal component of 3D system.&quot;], ## AREA[&quot;World.&quot;], ## BBOX[-90,-180,90,180]], ## ID[&quot;EPSG&quot;,4326]] st_crs printed out a lot of information, but the important things to note are that we (the user) inputted EPSG: 4326, its datum is World Geodetic System 1984 (or WGS 84), its axes are latitude and longitude, and its units are degree (as opposed to a linear unit like m that we might see in a projected crs). Its always good practice to double check the CRS of your object before you perform any analysis. Note that now when we look at the class of sites_sf it has two classes: sf and data.frame. class(sites_sf) ## [1] &quot;sf&quot; &quot;data.frame&quot; This is one of the great things about sf: because sf objects remain as class data.frame, it makes it easy to work with an sf object like you would with any data frame. Now that its a spatial object, lets plot it and see what it looks like! plot(sites_sf, pch = 16) This object only has one attribute (Site). If it had more than one, plotting in base R (i.e. using the plot function) plots all attributes (it will actually only plot 10 and will give you a warning if there are more than 10 attributes). To just plot the features shape, we can use st_geometry to extract the geometry of the vector plot(st_geometry(sites_sf), pch = 16) We can also use ggplot2 to plot sf objects. ggplot2 has a function called geom_sf, which makes it easy to visualize sf objects with ggplot2 ggplot(sites_sf) + geom_sf() # note that we don&#39;t need to tell ggplot what it should consider x and y to be; that&#39;s already built in with the &quot;geometry&quot; column! Remember, though, that this workshop will not cover how to make nice maps in R (that will be in the next workshop). I just bring this up because you would want to be sure the data youre working with looks like what you might expect it to, so you would want to make a quick plot before moving on to analysis. With sp Lets do the same thing but now with the sp package. Well use the function coordinates. This function will pull the coordinates from an object of class Spatial, but it will also assign coordinates to an object of class data.frame and automatically convert it to a Spatial object by following this format: coordinates(my_dataframe) &lt;- c(&quot;x&quot;, &quot;y&quot;) # x &amp; y are the NAMES of the columns # OR coordinates(my_dataframe) &lt;- c(1, 2) # 1 &amp; 2 are the INDICES of the columns Im first going to make a duplicate object of sites called sites_sp because coordinates will overwrite the original data.frame object into a Spatial object (which is not necessarily a bad thing, but sometimes you want to keep all your objects separate in case you need to use the original data frame for some reason) sites_sp &lt;- sites coordinates(sites_sp) &lt;- c(&quot;Longitude&quot;, &quot;Latitude&quot;) sites_sp ## class : SpatialPointsDataFrame ## features : 10 ## extent : -113.5013, -109.2163, 37.55458, 41.5076 (xmin, xmax, ymin, ymax) ## crs : NA ## variables : 1 ## names : Site ## min values : 1 ## max values : 10 Just like with sf, printing the object in sp will also show some information about that object, namely the class, extent, and CRS. And just like with sf we can use functions to look at this information for a Spatial object: class, bbox, and proj4string class(sites_sp) ## [1] &quot;SpatialPointsDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; bbox(sites_sp) ## min max ## Longitude -113.50131 -109.2163 ## Latitude 37.55458 41.5076 proj4string(sites_sp) ## [1] NA The CRS right now is NA. With sf we were able to assign a CRS while also converting the data frame to a simple feature, but with sp we need to do that in a separate step. Well use proj4string again as this function not only checks the CRS of a spatial object but can also be used to assign a CRS. In sf, we could give the function the EPSG code itself, but in sp we need to give it a character string wrapped in the function CRS. There are a few ways to write this character string, but the easiest one to remember, in my opinion, follows this format: \"+init=epsg:####\" (where #### would be the EPSG code) proj4string(sites_sp) &lt;- CRS(&quot;+init=epsg:4326&quot;) proj4string(sites_sp) ## [1] &quot;+proj=longlat +datum=WGS84 +no_defs&quot; Great! Now lets plot it to make sure it looks like what we would expect it to plot(sites_sp, pch = 16) # it defaults, for some reason, to a cross shape, so this changes it to a filled in circle It is not as straightforward to plot an object of class Spatial with ggplot2 as it was with sf, so I would recommend either converting the object to sf (which we will cover later in this chapter) or just plotting from the data frame ggplot(sites) + geom_point(aes(x = Longitude, y = Latitude)) 3.1.2 Loading vector data A lot of the time, you will have spatial data already saved as a shapefile. How do we load that into R? with sf Well use the function st_read which takes two arguments: dsn (data source name), which is essentially the folder where the shapefile is located, and layer, which is the name of file (without any extensions). layer is technically optional because dsn will choose the first file in that folder, so if the shapefile is the only file in that folder, then dsn will automatically choose the file. But I like to specify the layer name to avoid any mishaps. # Shapefile: freeways in Utah fwy_sf &lt;- st_read(dsn = &quot;Data/Examples/utah_freeway&quot;, layer = &quot;utah_freeway&quot;) ## Reading layer `utah_freeway&#39; from data source ## `C:\\Users\\a02351338\\Box\\Ecology Center\\R_Spatial_bookdown\\Data\\Examples\\utah_freeway&#39; ## using driver `ESRI Shapefile&#39; ## Simple feature collection with 1849 features and 7 fields ## Geometry type: LINESTRING ## Dimension: XY ## Bounding box: xmin: -114.0437 ymin: 37.00002 xmax: -109.0513 ymax: 42.00117 ## Geodetic CRS: WGS 84 Youll note that as we read in a shapefile with st_read, it automatically prints out the information about this feature (if you dont want R to print this, put quiet = FALSE in the function). Again, we can check this information separately (in case we forget or we need to check later in the analysis). We can also check the first few rows of the data frame to see what kind of attributes there are, and we can plot the feature to make sure it looks like what we expect it to be. st_bbox(fwy_sf) ## xmin ymin xmax ymax ## -114.04367 37.00002 -109.05128 42.00117 st_crs(fwy_sf) ## Coordinate Reference System: ## User input: WGS 84 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;latitude&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;longitude&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4326]] head(fwy_sf) ## Simple feature collection with 6 features and 7 fields ## Geometry type: LINESTRING ## Dimension: XY ## Bounding box: xmin: -112.0148 ymin: 40.12468 xmax: -111.6544 ymax: 41.24017 ## Geodetic CRS: WGS 84 ## OBJECTID FULLNAME NAME POSTTYPE SPEED_LMT UNIQUE_ID ## 1 898 I-80 EB FWY I-80 EB FWY 65 12TVL21421309_I-80 EB_FWY ## 2 1372 I-15 NB FWY I-15 NB FWY 65 12TVK44214181_I-15 NB_FWY ## 3 1374 I-84 WB FWY I-84 WB FWY 70 12TVL528848324_I-84 WB_FWY ## 4 1727 I-15 NB FWY I-15 NB FWY 70 12TVL14996575_I-15 NB_FWY ## 5 1955 I-84 WB FWY I-84 WB FWY 65 12TVL43954376_I-84 WB_FWY ## 6 2062 I-15 NB FWY I-15 NB FWY 65 12TVL22992231_I-15 NB_FWY ## Shape__Len geometry ## 1 331.34350 LINESTRING (-111.9295 40.76... ## 2 87.78441 LINESTRING (-111.6551 40.12... ## 3 1030.55015 LINESTRING (-111.9096 41.13... ## 4 442.62095 LINESTRING (-112.0148 41.24... ## 5 423.15540 LINESTRING (-111.6685 41.04... ## 6 489.79063 LINESTRING (-111.9144 40.84... ggplot(fwy_sf) + geom_sf() with sp To read in spatial data as an object in the Spatial family, we need to use the rgdal package. (When you load in rgdal, it will also automatically load in sp). Well use the rgdal function readOGR. This function is similar to st_read in that its arguments are dsn and layer which work exactly the same way as they do in st_read fwy_sp &lt;- readOGR(dsn = &quot;Data/Examples/utah_freeway&quot;, layer = &quot;utah_freeway&quot;) ## OGR data source with driver: ESRI Shapefile ## Source: &quot;C:\\Users\\a02351338\\Box\\Ecology Center\\R_Spatial_bookdown\\Data\\Examples\\utah_freeway&quot;, layer: &quot;utah_freeway&quot; ## with 1849 features ## It has 7 fields read_OGR, also like st_read, will print out some information after reading in the shapefile. If you want to turn this off, you can add verbose = FALSE in the functions arguments. Lets check the features information (class, extent, and CRS) and plot it class(fwy_sp) ## [1] &quot;SpatialLinesDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; bbox(fwy_sp) ## min max ## x -114.04367 -109.05128 ## y 37.00002 42.00117 proj4string(fwy_sp) ## [1] &quot;+proj=longlat +datum=WGS84 +no_defs&quot; plot(fwy_sp) 3.1.3 Projecting vector data So far all of our vector data has only been in WGS 84 lat/long CRS. More than likely you will want to work in a projected coordinate system. So how do we re-project (or transform) features in R? In sf well use the function st_transform() In sp well use the function spTransform() Both of these functions need the object you want to re-project and the target CRS. What CRS should we work in? Like I said earlier, UTM is a popular projection because its localized and allows you to work with with linear metrics like length, area, and distance. Since both of these features (our site data and Utah freeways) are located in Utah, we would use UTM 12N. We can stay in the WGS 84 datum, but for the purposes of demonstration, lets change to NAD83. (Remember from the previous chapter that there is not much difference between these datums, so its up to you if you want to use a more localized datum (NAD83) or a more recent datum (WGS84)). The EPSG code for NAD83 UTM 12N is 26912. (If you want to work in WGS84 UTM 12N, the EPSG code is 32612) # sf fwy_sf_proj &lt;- st_transform(fwy_sf, crs = 26912) st_crs(fwy_sf_proj) ## Coordinate Reference System: ## User input: EPSG:26912 ## wkt: ## PROJCRS[&quot;NAD83 / UTM zone 12N&quot;, ## BASEGEOGCRS[&quot;NAD83&quot;, ## DATUM[&quot;North American Datum 1983&quot;, ## ELLIPSOID[&quot;GRS 1980&quot;,6378137,298.257222101, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4269]], ## CONVERSION[&quot;UTM zone 12N&quot;, ## METHOD[&quot;Transverse Mercator&quot;, ## ID[&quot;EPSG&quot;,9807]], ## PARAMETER[&quot;Latitude of natural origin&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8801]], ## PARAMETER[&quot;Longitude of natural origin&quot;,-111, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8802]], ## PARAMETER[&quot;Scale factor at natural origin&quot;,0.9996, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8805]], ## PARAMETER[&quot;False easting&quot;,500000, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8806]], ## PARAMETER[&quot;False northing&quot;,0, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8807]]], ## CS[Cartesian,2], ## AXIS[&quot;(E)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;metre&quot;,1]], ## AXIS[&quot;(N)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;metre&quot;,1]], ## USAGE[ ## SCOPE[&quot;Engineering survey, topographic mapping.&quot;], ## AREA[&quot;North America - between 114Â°W and 108Â°W - onshore and offshore. Canada - Alberta; Northwest Territories; Nunavut; Saskatchewan. United States (USA) - Arizona; Colorado; Idaho; Montana; New Mexico; Utah; Wyoming.&quot;], ## BBOX[31.33,-114,84,-108]], ## ID[&quot;EPSG&quot;,26912]] # sp sites_sp_proj &lt;- spTransform(sites_sp, &quot;+init=epsg:26912&quot;) proj4string(sites_sp_proj) ## [1] &quot;+proj=utm +zone=12 +datum=NAD83 +units=m +no_defs&quot; Note that the coordinates of the WGS84 object compared the coordinates of the projected object are different. st_geometry(fwy_sf) ## Geometry set for 1849 features ## Geometry type: LINESTRING ## Dimension: XY ## Bounding box: xmin: -114.0437 ymin: 37.00002 xmax: -109.0513 ymax: 42.00117 ## Geodetic CRS: WGS 84 ## First 5 geometries: ## LINESTRING (-111.9295 40.76479, -111.9324 40.76... ## LINESTRING (-111.6551 40.12468, -111.6547 40.12... ## LINESTRING (-111.9096 41.13769, -111.9089 41.13... ## LINESTRING (-112.0148 41.24017, -112.0145 41.23... ## LINESTRING (-111.6685 41.04395, -111.6653 41.0424) st_geometry(fwy_sf_proj) ## Geometry set for 1849 features ## Geometry type: LINESTRING ## Dimension: XY ## Bounding box: xmin: 242993.7 ymin: 4098090 xmax: 668288.9 ymax: 4651339 ## Projected CRS: NAD83 / UTM zone 12N ## First 5 geometries: ## LINESTRING (421549.3 4513062, 421304.4 4513119) ## LINESTRING (444185.1 4441802, 444220.4 4441825,... ## LINESTRING (423663.9 4554441, 423720.3 4554432,... ## LINESTRING (414965.3 4565915, 414986 4565753, 4... ## LINESTRING (443817.3 4543851, 444084.9 4543677) The coordinates for the object in WGS84 are in lat/long and the units are decimal degrees. The coordiantes for the projected object are in UTM and the untis are meters. REMINDER: You should always double-check the CRS of every feature and object youre working with because you want to make sure everything is projected to the same CRS! If theyre not, it could result in inaccurate analysis and plotting. Depending on what functions youre using, R may give you a warning or error that the CRS of one feature and another dont match, but its best not to rely on this and just double-check yourself. 3.1.4 Saving vector data Once youve created or modified a spatial object, most likely you want to save it so you can use it later or share with collaborators. There are many files types that can hold spatial data, but the most commonly used are ESRI Shapefile (which can be used in ArcGIS software), KML (which can be used with Google Earth Engine), GeoJSON, and PostgreSQL. If youre curious what other file types are out there, you can use functions st_drivers() or ogrDrivers() for sf and sp respectively. In this workshop, I will focus just on ESRI Shapefiles. If youve worked with shapefiles before, youve likely noticed that a shapefile is actually a collection of files with the extensions .dbf, .prj, .shp, and .shx. Its often easier to organize and share shapefiles if theyre in their own folder. If you dont already have a folder ready for any shapefiles that youre ready to save, you can, of course, manually make one in the File Explorer. But you can also create folders in R! I, personally, often like to do this because it helps streamline my process. To do so well use the functions dir.exists() to check if the directory (or folder) or not, and if it doesnt well use dir.create() to create a directory. out_dir &lt;- &quot;Data/Examples/Sites_shp&quot; # name what you want the folder to be and save it in an object if(!dir.exists(out_dir)){ # this if statement is basically saying &quot;if out_dir does NOT exist...&quot; (the NOT is from the exclamation mark) dir.create(out_dir) # and if out_dir does NOT exist, then dir.create will create it } Now that weve created a new directory for this shapefile to go to, lets save our shapefile! For sf objects well use the function st_write and for Spatial* objects well use the function writeOGR. The arguments for these two functions are basically the same: they take the object youre saving, the dsn (or the folder) you want to save it to, the layer (or the name you want to save the file as, do NOT add an extension), and the driver (meaning if youre saving it as an ESRI Shapefile, KML, etc.) # sf st_write(sites_sf, dsn = out_dir, layer = &quot;Sites_sf&quot;, driver = &quot;ESRI Shapefile&quot;) # sp writeOGR(sites_sp, dsn = out_dir, layer = &quot;Sites_sp&quot;, driver = &quot;ESRI Shapefile&quot;) In reality I would only be working with either an sf object or a Spatial* object and I wouldnt save both (because once theyre saved as a shapefile, they are exactly the same file). 3.1.5 Converting between sf and sp As I mentioned before, there is no reason to not use both sf and Spatial* objects in one piece of code, but it doesnt make sense to load or create a single object as both an sf and Spatial* class. In some cases it makes more sense to work with sf objects and then convert them to Spatial* if needed (or vice versa). Lucky for us, its pretty easy to convert an sf object to Spatial* and then back to sf. For sf -&gt; Spatial* well use the function as() or as_Spatial(). For Spatial* -&gt; sf well use a function weve allready used: st_as_sf() # convert sf object to Spatial class(fwy_sf) ## [1] &quot;sf&quot; &quot;data.frame&quot; fwy_sf_to_sp &lt;- as_Spatial(fwy_sf) class(fwy_sf_to_sp) ## [1] &quot;SpatialLinesDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; # you can also use the function as() and add an argument &quot;Spatial&quot; fwy_sf_to_sp_2 &lt;- as(fwy_sf, &quot;Spatial&quot;) identical(fwy_sf_to_sp, fwy_sf_to_sp_2) # they are exactly the same ## [1] TRUE # convert Spatial object to sf class(fwy_sp) ## [1] &quot;SpatialLinesDataFrame&quot; ## attr(,&quot;package&quot;) ## [1] &quot;sp&quot; fwy_sp_to_sf &lt;- st_as_sf(fwy_sp) class(fwy_sp_to_sf) ## [1] &quot;sf&quot; &quot;data.frame&quot; A note about sf and tidyverse As I mentioned earlier, sf works really well with tidyverse. If you are familiar with tidyverse then you know that one pro is the pipe (%&gt;%) which lets you perform multiple functions at once without getting cluttered and hard to read. Functions for sf can easily be incorporated into the tidyverse piping method as well. For an example, we can load a csv file, covert it to an sf object, project it, and save it all at once using the pipes. read.csv(&quot;Data/Examples/Sites.csv&quot;) %&gt;% st_as_sf(coords = c(&quot;Longitude&quot;, &quot;Latitude&quot;), crs = 4326) %&gt;% st_transform(crs = 26912) %&gt;% st_write(dsn = &quot;data&quot;, layer = &quot;Sites_shp&quot;, driver = &quot;ESRI Shapefile&quot;) Of course, this requires that you already know what the column names for the coordinates are, and this might not be the best example for a series of functions to use with the pipe. But this type of process is a useful tool to know, especially if you are already familiar with and frequently use tidyverse. Your Turn! In the attached worksheet, there are some exerices to help you practice these concepts and functions. Try them out! 3.2 Rasters The primary package that deals with rasters is raster. Note that raster depends on the sp package, as it loads sp automatically when you load raster. (terra also works with rasters but is funcitonally very similar to raster). 3.2.1 Load a raster When you want to load a raster that is saved in a directory, youll use the (aptly named) function raster. When loading a raster that is already saved, the only argument you need is the filename (including the directory and extension) elev &lt;- raster(&quot;Data/Examples/elevation.tif&quot;) elev ## class : RasterLayer ## dimensions : 334, 390, 130260 (nrow, ncol, ncell) ## resolution : 0.000278, 0.000278 (x, y) ## extent : -114.0275, -113.9191, 36.40381, 36.49667 (xmin, xmax, ymin, ymax) ## crs : +proj=longlat +datum=WGS84 +no_defs ## source : elevation.tif ## names : elevation ## values : 645.7881, 1137.67 (min, max) When we examine the raster (by simply calling the object like we did above), we get a lot of useful information. class: the class of the raster (this could be RasterLayer, RasterStack, or RasterBrick) dimensions: the number of rows, columns, and cells resolution: the size of the cells extent: the min/max x and y crs: the coordinate reference system values: the min/max values this raster contains I recommend always examining a raster after you load it in to make sure the information looks like what you would expect it to be. You can also check all of this information with separate functions: class(elev) ## [1] &quot;RasterLayer&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; nrow(elev) ## [1] 334 ncol(elev) ## [1] 390 ncell(elev) ## [1] 130260 res(elev) # the cell resolution of the raster ## [1] 0.000278 0.000278 extent(elev) ## class : Extent ## xmin : -114.0275 ## xmax : -113.9191 ## ymin : 36.40381 ## ymax : 36.49667 proj4string(elev) # alternatively, we can use crs(r) which will print out a lot more information. proj4string() is sufficient ## [1] &quot;+proj=longlat +datum=WGS84 +no_defs&quot; summary(values(elev)) # put this in summary() so we can get an idea of the spread of values (rather than a list of all of the values themselves) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 645.8 798.5 869.5 864.4 932.0 1137.7 We can also plot the raster to check that it looks like what we would expect it to be plot(elev) We can also plot a raster with ggplot2, but we need to do an extra step of converting it to a data frame first. Well use the base R function as.data.frame and we need to be sure to put xy = TRUE in the arguments. After we do that, we can use the function geom_raster() within ggplot. Within the aes() function in geom_raster(), we need to put the columns that correspond to the x and y locations and what the fill value should represent (in this case, elevation). elev_df &lt;- as.data.frame(elev, xy = TRUE) head(elev_df) # the data frame of a raster contains columns for the x and y locations and the corresponding cell value ## x y elevation ## 1 -114.0274 36.49653 1082.456 ## 2 -114.0271 36.49653 1081.739 ## 3 -114.0268 36.49653 1080.975 ## 4 -114.0265 36.49653 1079.712 ## 5 -114.0262 36.49653 1077.750 ## 6 -114.0260 36.49653 1075.466 ggplot(elev_df) + geom_raster(aes(x = x, y = y, fill = elevation)) # You can use the pipe to run this process all at once elev %&gt;% as.data.frame(xy = TRUE) %&gt;% ggplot() + geom_raster(aes(x = x, y = y, fill = elevation)) # This requires that you know the column name of the raster values An important thing to note is that, depending on the size of the raster, it might be too computationally expensive to convert a raster to a data frame and R may give you an error. (Another reminder that we will not cover how to make these maps look nice, this is just a quick way to check that your raster looks the way that you think it should) Loading a raster with more than one band In the example above, the raster we loaded only had one band. Lets try loading in a raster downloaded from SNODAS (Snow Data Assimilation System) which has 2 bands: SWE (snow water equivalent) and snow depth. (SNODAS offers daily rasters, and this example raster is from 02-23-2019). snow &lt;- raster(&quot;Data/Examples/snow_20190223.tif&quot;) snow ## class : RasterLayer ## band : 1 (of 2 bands) ## dimensions : 12, 13, 156 (nrow, ncol, ncell) ## resolution : 0.008333333, 0.008333333 (x, y) ## extent : -114.025, -113.9167, 36.4, 36.5 (xmin, xmax, ymin, ymax) ## crs : +proj=longlat +datum=WGS84 +no_defs ## source : snow_20190223.tif ## names : snow_20190223 ## values : 0, 24 (min, max) Notice how it says band 1 (of 2). If there are two bands, why did it only load 1? If we look in the help file for ?raster, it says that this function creates a RasterLayer object, meaning only 1 band. We can also see that theres an argument called band, meaning you can specify which band you want to load (and the default is the first band). We could load individual bands one-by-one, but thats tedious and, depending how many bands a raster stack has, could be lines and lines of repetitive code. Instead, well use the function stack() or brick() snow_stack &lt;- stack(&quot;Data/Examples/snow_20190223.tif&quot;) class(snow_stack) ## [1] &quot;RasterStack&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; snow_stack ## class : RasterStack ## dimensions : 12, 13, 156, 2 (nrow, ncol, ncell, nlayers) ## resolution : 0.008333333, 0.008333333 (x, y) ## extent : -114.025, -113.9167, 36.4, 36.5 (xmin, xmax, ymin, ymax) ## crs : +proj=longlat +datum=WGS84 +no_defs ## names : snow_20190223.1, snow_20190223.2 ## min values : 0, 0 ## max values : 24, 150 snow_brick &lt;- brick(&quot;Data/Examples/snow_20190223.tif&quot;) class(snow_brick) ## [1] &quot;RasterBrick&quot; ## attr(,&quot;package&quot;) ## [1] &quot;raster&quot; snow_brick ## class : RasterBrick ## dimensions : 12, 13, 156, 2 (nrow, ncol, ncell, nlayers) ## resolution : 0.008333333, 0.008333333 (x, y) ## extent : -114.025, -113.9167, 36.4, 36.5 (xmin, xmax, ymin, ymax) ## crs : +proj=longlat +datum=WGS84 +no_defs ## source : snow_20190223.tif ## names : snow_20190223.1, snow_20190223.2 ## min values : 0, 0 ## max values : 24, 150 When we call the stack and the brick, they look identical besides the class. So what are the differences between a stack and brick? When we look at ?brick, the help file tells us a few differences. Both a RasterStack and RasterBrick are multi-layer raster objects, but processing time is shorter with a RasterBrick. However. a RasterBrick is less flexible than a RasterStack because it can only be created from a single file, while a RasterStack could be fed a list of file names or raster objects and automatically stack them all together. For the purposes of this example, a stack and a brick are essentially identical. Lets plot the raster stack just to make sure it looks like what we might expect: plot(snow_stack) Note that plotting a raster stack (or brick) will plot all the layers at once. The benefit of working with a stack of rasters is that if you need to perform a computation on all of your rasters, you can stack them all togther and the computation will run for every raster layer in the stack. However, rasters will only stack together if they have the same dimensions, resolution, extent, and crs. For example, if we try to stack our elevation raster and stack of snow rasters together: stack(elev, snow_stack) Error in compareRaster(x) : different extent We get an error that the extents dont match extent(elev) ## class : Extent ## xmin : -114.0275 ## xmax : -113.9191 ## ymin : 36.40381 ## ymax : 36.49667 extent(snow_stack) ## class : Extent ## xmin : -114.025 ## xmax : -113.9167 ## ymin : 36.4 ## ymax : 36.5 Theyre very close, but they need to be exact. Why cant I just not stack them and run seperate computations on these rasters? You can, but your raster cells will be slightly off from each other and may result in inaccurate results and inference. Figure 3.1: A stack of rasters, showing how each cell would correspond to the ones on top and below In a future section, well talk about how to make your rasters line up so you can stack them all together. 3.2.2 Create a raster To create a raster from scratch, well use the same function raster() but instead of the filename or band as arguments, well include the extent and resolution that we want. In this example, lets just make something random. set.seed(1) # this is to make the randomness of runif the same every time x &lt;- runif(1, min = 0, max = 10) y &lt;- runif(1, min = 0, max = 10) r_new &lt;- raster(xmn = x, xmx = x + 10, ymn = y, ymx = y + 10, resolution = 1) r_new ## class : RasterLayer ## dimensions : 10, 10, 100 (nrow, ncol, ncell) ## resolution : 1, 1 (x, y) ## extent : 2.655087, 12.65509, 3.721239, 13.72124 (xmin, xmax, ymin, ymax) ## crs : +proj=longlat +datum=WGS84 +no_defs Note that because we didnt specify the CRS in the arguments, it defaulted to WGS84 lat/long. Right now this raster is empty. We can check with the function values() head(values(r_new)) ## [1] NA NA NA NA NA NA Well use the same function to assign fill the raster with values. If you noticed, there are 100 total cells that need to be filled, and lets fill them with random numbers. values(r_new) &lt;- runif(100) head(values(r_new)) ## [1] 0.5728534 0.9082078 0.2016819 0.8983897 0.9446753 0.6607978 r_new ## class : RasterLayer ## dimensions : 10, 10, 100 (nrow, ncol, ncell) ## resolution : 1, 1 (x, y) ## extent : 2.655087, 12.65509, 3.721239, 13.72124 (xmin, xmax, ymin, ymax) ## crs : +proj=longlat +datum=WGS84 +no_defs ## source : memory ## names : layer ## values : 0.01339033, 0.9919061 (min, max) plot(r_new) Why would you need to create a raster from scratch? If youve written code to perform a calculation or an analysis on a raster, its good to check that your code is doing what you think its doing. A good way to test the code is to try it out on a dummy raster If youre asking for help on your code (on Stack Overflow for example), its good practice to either include your data (which is often very difficult to do) or to create a reproducible example. Knowing how to create fake data or fake rasters is useful to know. Well see in the next section another useful reason for creating a raster from scratch. 3.2.3 Project a raster Lets go back to the elevation raster we loaded earlier. If you noticed, the CRS of this raster is WGS84 UTM12N, as opposed to NAD83 UTM12N that we used earlier for our vector data. proj4string(elev) ## [1] &quot;+proj=longlat +datum=WGS84 +no_defs&quot; If we were going to do some sort of analysis on our vector data and raster data, we want all of our spatial objects to be in the same CRS so that we know that our layers are truly stacked on top of the other (for plotting and analysis). For that reason, we need to project this raster to NAD83 UTM12N. To do so, well use the function projectRaster elev_proj &lt;- projectRaster(elev, crs = &quot;+init=epsg:26912&quot;) elev_proj ## class : RasterLayer ## dimensions : 354, 415, 146910 (nrow, ncol, ncell) ## resolution : 24.9, 30.8 (x, y) ## extent : 228349.4, 238682.9, 4032553, 4043456 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : memory ## names : elevation ## values : 645.8186, 1136.32 (min, max) Wait, lets take a look at the cell resolution again res(elev_proj) ## [1] 24.9 30.8 This elevation raster came from the USGSs 3D Elevation Program. When I downloaded it, I specified a 1-arcsecond resolution (arcsecond is the unit for long/lat projections), which is equivalent to a 30mX30m resolution in a linear projection (like UTM). So why is the resolution after projecting not actually 30mX30m? Whats happening is that every cell needs to be projected, causing the cells to be warped and results in slightly off cell measurements. What if we tried specifying the cell resolution in the projectRaster function? elev_proj_2 &lt;- projectRaster(elev, crs = &quot;+init=epsg:26912&quot;, res = 30) elev_proj_2 ## class : RasterLayer ## dimensions : 363, 345, 125235 (nrow, ncol, ncell) ## resolution : 30, 30 (x, y) ## extent : 228348.8, 238698.8, 4032562, 4043452 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : memory ## names : elevation ## values : 645.8673, 1137.32 (min, max) We could do this. But can we be sure that all of the cells in this raster would align one-to-one in all of our other rasters? And if they dont align, can we be sure our analysis and computation on all of our rasters would be correct? snow_proj &lt;- projectRaster(snow_stack, crs = &quot;+init=epsg:26912&quot;, res = 30) snow_proj ## class : RasterBrick ## dimensions : 389, 345, 134205, 2 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 228559.8, 238909.8, 4032145, 4043815 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : memory ## names : snow_20190223.1, snow_20190223.2 ## min values : -8.835303, -49.926375 ## max values : 23.99968, 157.71859 stack(elev_proj_2, snow_proj) Error in compareRaster(x) : different extent Furthermore, theres something else happening when rasters are projected. Lets double-check the help file, ?projectRaster. It looks like theres another argument called method that defaults to \"bilinear\". If you scroll down to the details of method, it says it can either take ngb (or nearest neighbor) or bilinear (or bilinear interpolation). Okwell what does that mean? Bilinear interpretation is basically a way of estimating a value in between two other values. Nearest neighbor essentially picks the exact value of a point thats closest to the focal point. This essentially means that when you use projectRaster, the raster cells are being warped and shifted slightly, so R cant just simply move the entire raster over, but it needs to know how to estimate the cell values in their new location and new resolution. So should it estimate a value in between two cell values or pick the actual value of the cell its closest to? Either way, this will slighlty adjust the data: elev_bilinear &lt;- projectRaster(elev, crs = &quot;+init=epsg:26912&quot;, res = 30, method = &quot;bilinear&quot;) elev_ngb &lt;- projectRaster(elev, crs = &quot;+init=epsg:26912&quot;, res = 30, method = &quot;ngb&quot;) # check the spread of values in the orginal raster summary(values(elev)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 645.8 798.5 869.5 864.4 932.0 1137.7 # check the spread of values in the raster estimated with bilinear summary(values(elev_bilinear)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 645.9 798.4 869.5 864.4 932.1 1137.3 13855 # check the spread of values in the raster estimated with nearest neighbor summary(values(elev_ngb)) ## Min. 1st Qu. Median Mean 3rd Qu. Max. NA&#39;s ## 646.0 798.5 869.5 864.4 932.0 1137.7 13855 Theres no right or wrong answer on which method you pick. The projectRaster help file recommends using bilinear for continuous rasters (like this elevation raster were working with) and ngb for categorical rasters (in fact, you probably shouldnt use bilinear for categorical rasters because it will pick a value thats in between two values which arent real numbers, but are actually stand-ins for a category). In my work I use ngb for continous rasters as well, so Im going to use that for these examples, but bilinear is valid to use as well. (Again, as with everything, it depends on your analysis and your system.) One thing to keep in mind with projecting rasters is that you should not over-project and re-sample your rasters over and over again. Imagine printing a picture and then making a copy of that printed picture. And then making a copy of the copy. And then a copy of that that copy. Over and over again. Eventually you end up with a warped image that only vaguely resembles the original image. A similar thing can happen if you project and re-sample your rasters even more than once. In contrast, there is no issue with projecting and re-projecting your vector data over and over again. Ok, so now that we know the dangers of projecting rasters, what is the best way project a raster? I recommend (and projectRaster also recommends) creating a template raster and using that template as a mold for all of your rasters. (hint: this is where it comes in handy to know how to make a blank raster) So lets create a template raster with our desired CRS, cell resolution, and extent. To choose the cell resolution, I recommend picking your set of rasters with the smallest resolution (but keep in mind that this will affect disk space and computation time, so again theres no right or wrong answer). In this case, elevation (30mX30m) has a smaller resolution than snow (1kmX1km). The extent should be the min and max area of focus, such as your study area. # create a blank raster with desired parameters. We don&#39;t need to add any values to it template &lt;- raster(crs = &quot;+init=epsg:26912&quot;, resolution = c(30, 30), xmn = 228560, xmx = 238910, ymn = 4032145, ymx = 4043815) template ## class : RasterLayer ## dimensions : 389, 345, 134205 (nrow, ncol, ncell) ## resolution : 30, 30 (x, y) ## extent : 228560, 238910, 4032145, 4043815 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs # use the template to project our rasters # from = focal raster # to = the raster object with the desired parameters # method = the method to compute new values elev_proj_template &lt;- projectRaster(from = elev, to = template, method = &quot;ngb&quot;) snow_proj_template &lt;- projectRaster(from = snow_stack, to = template, method = &quot;ngb&quot;) elev_proj_template ## class : RasterLayer ## dimensions : 389, 345, 134205 (nrow, ncol, ncell) ## resolution : 30, 30 (x, y) ## extent : 228560, 238910, 4032145, 4043815 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : memory ## names : elevation ## values : 645.9824, 1137.67 (min, max) snow_proj_template ## class : RasterBrick ## dimensions : 389, 345, 134205, 2 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 228560, 238910, 4032145, 4043815 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : memory ## names : snow_20190223.1, snow_20190223.2 ## min values : 0, 0 ## max values : 24, 150 # now we can stack them! This way we know for sure that all cells align with every layer stack &lt;- stack(elev_proj_template, snow_proj_template) stack ## class : RasterStack ## dimensions : 389, 345, 134205, 3 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 228560, 238910, 4032145, 4043815 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## names : elevation, snow_20190223.1, snow_20190223.2 ## min values : 645.9824, 0.0000, 0.0000 ## max values : 1137.67, 24.00, 150.00 plot(stack) Right now the bands names (besides elevation) are not very descriptive, but we can change their names so that we can more easily remember which band is which. In this case, band 1 is elevation, band 2 is SWE, and band 3 is snow depth. To change the band names, well use the function names() names(stack) &lt;- c(&quot;elevation&quot;, &quot;swe&quot;, &quot;snow_depth&quot;) stack ## class : RasterStack ## dimensions : 389, 345, 134205, 3 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 228560, 238910, 4032145, 4043815 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## names : elevation, swe, snow_depth ## min values : 645.9824, 0.0000, 0.0000 ## max values : 1137.67, 24.00, 150.00 3.2.4 Save a raster To save a raster well use the function writeRaster. We need to include the raster object that were saving, the full file name (including the directory but not the file extension), and the format (i.e. the file type) we want to save the raster as. The two most common formats are raster (which creates two files with the extensions .gri and .grd) &amp; GTiff (GeoTIFF, which creates a file with the extension .tif). I personally use GeoTIFFs, but a pro for using raster is that it saves the name of the raster layers that are in a stack. (You can also check writeFormats() for other formats to save a raster.) writeRaster(stack, &quot;Data/Examples/elev_snow_stack&quot;, format = &quot;GTIFF&quot;) Note that some raster functions have optional arguments to add filenames and formats so that the funciton will automatically save the output after performing its function. Your Turn! In the attached worksheet, there are some exerices to help you practice these concepts and functions. Try them out! Now that we know the basics of working with vector and raster data in R, lets learn how to manipulate and perform computations on these spatial objects. "],["spatial-analysis.html", "Chapter 4 Spatial Analysis 4.1 Selecting Attributes 4.2 Select features by location 4.3 Joining Attributes 4.4 Cropping 4.5 Extract Raster Values 4.6 Distance 4.7 Raster Cell Stats 4.8 Calculate Terrain Characteristics 4.9 A Note About Loops", " Chapter 4 Spatial Analysis Now lets do some analysis with the data weve acquired already: Sites point data sites_sf Utah freeways fwy_sf_proj We also have some data that Ive included in the exercises portion of the worksheet: a different elevation + snow raster stack (this one is in the NW corner of Utah), a set of plots as a point feature, and a polygon feature of boundaries in Utah and who manages them: elev_snow_stk ## class : RasterStack ## dimensions : 7401, 5606, 41490006, 3 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 414639.5, 582819.5, 4428230, 4650260 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## names : elevation, swe, snow_depth ## min values : 1279.897, 0.000, 0.000 ## max values : 4111.6, 1108.0, 3196.0 plot(elev_snow_stk) head(plots_sf) ## Simple feature collection with 6 features and 1 field ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 499102.7 ymin: 4528029 xmax: 560979.8 ymax: 4622779 ## Projected CRS: NAD83 / UTM zone 12N ## Plots geometry ## 1 A POINT (537889.7 4593484) ## 2 B POINT (560979.8 4586311) ## 3 C POINT (544094.8 4548330) ## 4 D POINT (522850.5 4556870) ## 5 E POINT (551238.5 4528029) ## 6 F POINT (499102.7 4622779) manage_sf &lt;- st_read(&quot;data/Exercises/UT_land_management&quot;, &quot;UT_land_management&quot;, quiet = T) %&gt;% st_transform(crs = 26912) manage_sp &lt;- as(manage_sf, &quot;Spatial&quot;) ## Simple feature collection with 6 features and 5 fields ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: 388066 ymin: 4410117 xmax: 403492.2 ymax: 4414856 ## Projected CRS: NAD83 / UTM zone 12N ## OBJECTID OWNER AGENCY ADMIN DESIG geometry ## 1 1 Federal BLM BLM Bankhead Jones MULTIPOLYGON (((388854 4411... ## 2 2 Federal BLM BLM Bankhead Jones MULTIPOLYGON (((394528.1 44... ## 3 3 Federal BLM BLM Bankhead Jones MULTIPOLYGON (((388473.6 44... ## 4 4 Federal BLM BLM Bankhead Jones MULTIPOLYGON (((399793.3 44... ## 5 5 Federal BLM BLM Bankhead Jones MULTIPOLYGON (((389300.1 44... ## 6 6 Federal BLM BLM Bankhead Jones MULTIPOLYGON (((403492.2 44... Lets plot one of the rasters with our sites point vector and Utah highways line vector. To plot just one raster layer in a stack we can either index it with double brackets or with the name: # these are different ways to get the same raster layer elev_snow_stk[[1]] ## class : RasterLayer ## band : 1 (of 3 bands) ## dimensions : 7401, 5606, 41490006 (nrow, ncol, ncell) ## resolution : 30, 30 (x, y) ## extent : 414639.5, 582819.5, 4428230, 4650260 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : elev_snow_nw_stack.tif ## names : elevation ## values : 1279.897, 4111.6 (min, max) elev_snow_stk$elevation ## class : RasterLayer ## band : 1 (of 3 bands) ## dimensions : 7401, 5606, 41490006 (nrow, ncol, ncell) ## resolution : 30, 30 (x, y) ## extent : 414639.5, 582819.5, 4428230, 4650260 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : elev_snow_nw_stack.tif ## names : elevation ## values : 1279.897, 4111.6 (min, max) plot(elev_snow_stk$elevation) lines(fwy_sp_proj, lwd = 2) # lines() will plot the polyline on top of the plot (instead of drawing a new plot) points(sites_sp_proj, pch = 16) # points() will do the same as lines() except with point data points(plots_sp, pch = 3) (This can also be done with ggplot using as.data.frame but in this case the raster may be too large for R to convert to a dataframe and plot) Lets start on some analysis and computations that we can run on these data. 4.1 Selecting Attributes Perhaps you have vector data and you want to select only certain attributes or attributes that reach a focal threshold. To do so we need to set up a logical statement, and we can do this in base R or in tidyverse. Lets say we want to select boundaries that are operated by BLM. In the shapefile of management boundaries, this information is located in the column AGENCY unique(manage_sf$AGENCY) ## [1] &quot;BLM&quot; &quot;BR&quot; &quot;DOD&quot; &quot;DOE&quot; &quot;NPS&quot; &quot;USFS&quot; &quot;USFWS&quot; ## [8] &quot;Private&quot; &quot;DNR&quot; &quot;OS&quot; &quot;SITLA&quot; &quot;UDOT&quot; &quot;Tribal&quot; In base R we can use the function which and in tidyverse we can use the function filter # base R blm_boundary &lt;- manage_sf[which(manage_sf$AGENCY == &quot;BLM&quot;), ] # you can do this with sp objects too # tidyverse blm_boundary &lt;- manage_sf %&gt;% # you cannot do this with sp objects filter(AGENCY == &quot;BLM&quot;) ggplot() + geom_sf(data = manage_sf, col = &quot;grey&quot;, size = 0.1) + geom_sf(data = blm_boundary, fill = &quot;red&quot;, col = &quot;grey30&quot;, alpha = 0.8, size = 0.1) Using these functions, you can set up any logical statement using ==, %in%, &gt;, &gt;=, &lt;, &lt;=, or ! and select for the specific attributes you need. 4.2 Select features by location Lets make select the management boundaries based on if they are intersected by a major highway. For sf well use the function st_intersect and for sp well use manage_roads &lt;- st_intersects(fwy_sf_proj, manage_sf) # the first argument is the target shape and the second argument the shape we&#39;re selecting from class(manage_roads) ## [1] &quot;sgbp&quot; &quot;list&quot; The output is an sgbp object, or Sparse Geometry Binary Predicate. Basically it returns a list of vectors of integers, which refer to the indices of each polygon that intersects. dim(manage_roads) ## [1] 1849 14888 nrow(fwy_sf_proj) ## [1] 1849 nrow(manage_sf) ## [1] 14888 So the dimensions of this list are the the number of rows in the target shape (the highways) and the number of rows in the intersecting shape (the management boundaries). If we wanted to know the specifc index of a specific road that intersected with a management boundary, it would be useful to keep all of these indices seperate. Since we just want to know which boundaries intersect a road, we can collapse this whole list together. manage_roads_index &lt;- unique(unlist(manage_roads)) # just pull the unique indices manage_roads_intersect &lt;- manage_sf[manage_roads_index, ] ggplot() + geom_sf(data = manage_sf, col = &quot;grey&quot;, size = 0.1) + geom_sf(data = manage_roads_intersect, fill = &quot;red&quot;, col = &quot;grey30&quot;, alpha = 0.8, size = 0.1) + geom_sf(data = fwy_sf_proj, col = &quot;black&quot;, size = 1) If you look at the help file for ?st_intersects, youll see there are a lot of different functions that select features based on another feature. 4.3 Joining Attributes Lets load in a table of some data collected at each plot ## Plots Species Date AboveGroundBiomass MeanHeight PercentCover ## 1 A R. maritimus 2021-05-01 27.61158 3.7257421 77.75151 ## 2 A B. cernua 2021-05-01 13.18637 4.5355917 65.06243 ## 3 A S. acutus 2021-05-01 68.84413 1.8172373 98.39445 ## 4 B R. maritimus 2021-05-02 59.58161 1.2949173 28.84727 ## 5 B B. cernua 2021-05-02 87.44708 0.7372426 48.40372 ## 6 B S. acutus 2021-05-02 35.32842 2.6436731 95.73950 Lets join this table to the Plots feature so we could do some spatial analysis and mapping of the collected data. To join two tables together, we need to input the two tables and the name of the column that exists in both tables (so the join function knows how to match attributes together). In this case, that would be the Plots column. head(plots_sf$Plots) ## [1] &quot;A&quot; &quot;B&quot; &quot;C&quot; &quot;D&quot; &quot;E&quot; &quot;F&quot; head(plot_data$Plots) ## [1] &quot;A&quot; &quot;A&quot; &quot;A&quot; &quot;B&quot; &quot;B&quot; &quot;B&quot; We can use the tidyverses join functions. (If you dont know how joins work, I would recommend looking at the help file by typing ?left_join in the console) plots_join &lt;- left_join(plots_sf, plot_data, by = &quot;Plots&quot;) head(plots_join) ## Simple feature collection with 6 features and 6 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 537889.7 ymin: 4593484 xmax: 537889.7 ymax: 4593484 ## Projected CRS: NAD83 / UTM zone 12N ## Plots Species Date AboveGroundBiomass MeanHeight PercentCover ## 1 A R. maritimus 2021-05-01 27.61158 3.7257421 77.75151 ## 2 A B. cernua 2021-05-01 13.18637 4.5355917 65.06243 ## 3 A S. acutus 2021-05-01 68.84413 1.8172373 98.39445 ## 4 A R. maritimus 2021-05-08 42.73997 0.5477968 65.87027 ## 5 A B. cernua 2021-05-08 68.90326 1.9793263 11.35618 ## 6 A S. acutus 2021-05-08 44.42221 0.4002126 90.92433 ## geometry ## 1 POINT (537889.7 4593484) ## 2 POINT (537889.7 4593484) ## 3 POINT (537889.7 4593484) ## 4 POINT (537889.7 4593484) ## 5 POINT (537889.7 4593484) ## 6 POINT (537889.7 4593484) Great! At this point you could then do some spatial analysis based on location, or make a map based on average biomass, for example. However, thats outside the scope of this workshop. Joining two tables together is a valuable tool to know, not just for GIS but for any data management. 4.4 Cropping Cropping a vector If you noticed earlier, the highway polyline runs outside of the elevation raster. What if we want to crop the vector so that it falls only within the raster? For sf well use the function st_crop (which requires an object of class sf or sfc and the min/max x &amp; y extent we want to crop the feature to). For sp well use the function crop. (crop is actually in the raster package, but remember that raster is dependent on sp? That means that some raster functions can be used on Spatial* objects too). For crop we need the object were cropping and the extent were cropping to (or an object that an extent can be derived from, in this case the raster itself) # sf: # First we need the extent of the raster that is compatible with sf. For that we&#39;ll use st_bbox() rast_ext &lt;- st_bbox(extent(elev_snow_stk)) rast_ext ## xmin ymin xmax ymax ## 414639.5 4428229.8 582819.5 4650259.8 fwy_crop_sf &lt;- st_crop(fwy_sf_proj, rast_ext) # sp: fwy_crop_sp &lt;- crop(fwy_sp_proj, elev_snow_stk) Cropping a raster We can also easily crop a raster. Lets say we wanted to crop our raster stack down to only the area around our site thats in the Uintas plot(elev_snow_stk$elevation) points(sites_sp_proj, pch = 16) Figure 4.1: the Uintas are that high-elevation mountain range in the middle right of this map First we need to find out what site number that is. Well use the text() function. There is a text() function for base R plotting, but the raster package adapted that function to plot text from rasters and Spatial* objects. Lets use that function, so we need to specify which package it comes from using raster:: plot(elev_snow_stk$elevation) raster::text(sites_sp_proj, labels = &quot;Site&quot;, halo = T) Site 8! Lets filter our spatial data to just this site. # base R site_8 &lt;- sites_sf_proj[which(sites_sf_proj$Site == 8), ] # remember that you can use this method for sp objects too # tidyverse site_8 &lt;- sites_sf_proj %&gt;% filter(Site == 8) site_8 ## Simple feature collection with 1 feature and 1 field ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 564670.6 ymin: 4513862 xmax: 564670.6 ymax: 4513862 ## Projected CRS: NAD83 / UTM zone 12N ## Site geometry ## 1 8 POINT (564670.6 4513862) But we dont want to crop the raster down to a single point, so lets first make a buffer (5kmX5km) around this specific site. Well use st_buffer() to do so. buffer &lt;- st_buffer(site_8, dist = 5000) # units are in meters buffer ## Simple feature collection with 1 feature and 1 field ## Geometry type: POLYGON ## Dimension: XY ## Bounding box: xmin: 559670.6 ymin: 4508862 xmax: 569670.6 ymax: 4518862 ## Projected CRS: NAD83 / UTM zone 12N ## Site geometry ## 1 8 POLYGON ((569670.6 4513862,... ggplot() + geom_sf(data = buffer) + geom_sf(data = site_8, col = &quot;red&quot;, size = 2) + coord_sf(datum = st_crs(26912)) # this plots the axes to UTM coordinates instead of latlong coordinates To crop a raster, well use the same function we used to crop a Spatial* object: crop. Remember that I said earlier that any function we perform on a stack of rasters will run for every raster in that stack! Earlier when we used crop, we could just put in the object itself and the function would automatically crop to the extent of that object. But that only works for objects of class Raster*, Spatial*, or Extent. Because our buffer is of class sf, we cant just put the object itself in. Instead we need to put in its extent (or you could convert the buffer to a Spatial* object) stack_crop &lt;- crop(elev_snow_stk, extent(buffer)) stack_crop ## class : RasterBrick ## dimensions : 333, 334, 111222, 3 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 559659.5, 569679.5, 4508870, 4518860 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : memory ## names : elevation, swe, snow_depth ## min values : 2714.15, 148.00, 680.00 ## max values : 3811.196, 427.000, 1453.000 plot(stack_crop) 4.5 Extract Raster Values What if we need to get data from our rasters at our specific site locations? We can use the function extract(). Lets load a landcover raster so we can classify the habitat types of our sites landcover &lt;- raster(&quot;Data/Examples/landcover.tif&quot;) landcover ## class : RasterLayer ## dimensions : 18675, 14838, 277099650 (nrow, ncol, ncell) ## resolution : 30, 30 (x, y) ## extent : 229319.6, 674459.6, 4094414, 4654664 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## source : landcover.tif ## names : landcover ## values : 137, 584 (min, max) plot(landcover) raster::text(sites_sp_proj, labels = &quot;Site&quot;, halo = T) extract returns a vector whose indices match the indices of the spatial object. We could leave it as a vector, or we could automatically attach it to the dataframe using $ sites_sf_proj$land_value &lt;- raster::extract(landcover, sites_sp_proj) sites_sf_proj ## Simple feature collection with 10 features and 2 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 287581.9 ymin: 4157301 xmax: 656513.7 ymax: 4595255 ## Projected CRS: NAD83 / UTM zone 12N ## Site geometry land_value ## 1 1 POINT (516801.7 4188305) 547 ## 2 2 POINT (470663.6 4322073) 491 ## 3 3 POINT (656513.7 4212358) 561 ## 4 4 POINT (311534.1 4398520) 498 ## 5 5 POINT (454023.6 4595255) 187 ## 6 6 POINT (455210.1 4289185) 151 ## 7 7 POINT (420826.5 4351553) 457 ## 8 8 POINT (564670.6 4513862) 152 ## 9 9 POINT (287581.9 4469956) 458 ## 10 10 POINT (377495.7 4157301) 158 Ok but what do these numbers mean? Our landcover raster is a categorical raster, so these numbers arent actually real numbers but represent a habitat type. Fortunately we have a dataframe indicating what these numbers mean. land_info &lt;- read.csv(&quot;Data/Examples/landcover_info.csv&quot;) head(land_info)[,1:5] ## Value ClassCode ClassName SubClassCode SubClassName ## 1 1 1 Forest &amp; Woodland 1.A Tropical Forest &amp; Woodland ## 2 2 1 Forest &amp; Woodland 1.A Tropical Forest &amp; Woodland ## 3 3 1 Forest &amp; Woodland 1.A Tropical Forest &amp; Woodland ## 4 4 1 Forest &amp; Woodland 1.A Tropical Forest &amp; Woodland ## 5 5 1 Forest &amp; Woodland 1.A Tropical Forest &amp; Woodland ## 6 6 1 Forest &amp; Woodland 1.A Tropical Forest &amp; Woodland The column Value corresponds to the cell value we extracted from the raster. We can use what we learned earlier how to join two tables together, but first we need to make sure the ID column (Value) for both tables are named the same. sites_sf_land &lt;- sites_sf_proj %&gt;% rename(Value = land_value) %&gt;% # rename the column so it matches in both tables left_join(land_info, by = &quot;Value&quot;) # join by the column &quot;Value&quot; head(sites_sf_land)[,1:6] ## Simple feature collection with 6 features and 6 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 311534.1 ymin: 4188305 xmax: 656513.7 ymax: 4595255 ## Projected CRS: NAD83 / UTM zone 12N ## Site Value ClassCode ClassName SubClassCode ## 1 1 547 6 Open Rock Vegetation 3.B ## 2 2 491 3 Desert &amp; Semi-Desert 3.B ## 3 3 561 9 Introduced &amp; Semi Natural Vegetation 9.A ## 4 4 498 3 Desert &amp; Semi-Desert 3.B ## 5 5 187 1 Forest &amp; Woodland 1.B ## 6 6 151 1 Forest &amp; Woodland 1.B ## SubClassName geometry ## 1 Cool Semi-Desert Scrub &amp; Grassland POINT (516801.7 4188305) ## 2 Cool Semi-Desert Scrub &amp; Grassland POINT (470663.6 4322073) ## 3 Introduced &amp; Semi Natural Vegetation POINT (656513.7 4212358) ## 4 Cool Semi-Desert Scrub &amp; Grassland POINT (311534.1 4398520) ## 5 Temperate &amp; Boreal Forest &amp; Woodland POINT (454023.6 4595255) ## 6 Temperate &amp; Boreal Forest &amp; Woodland POINT (455210.1 4289185) Awesome! 4.6 Distance Lets say we needed to know how far from a major road each of our sites are. Well use the function st_distance for our sf objects. We simply need to input the focal feature (the sites) and the feature dist &lt;- st_distance(sites_sf_proj, fwy_sf_proj) dim(dist) ## [1] 10 1849 What did this do? Why are there so many columns? Remember that our Utah highways feature is a polyline, meaning its a line of lines. If we look at the dimensions of the highways feature: nrow(fwy_sf_proj) ## [1] 1849 There are 1849 lines (i.e. roads) that make up this whole feature. So st_distance found the distance for each site (the number of rows) for every road (the number of columns). This could be useful information, but presumably we want just the distance of the closest road. To find that distance, well have to do some data frame manipulation. dist_df &lt;- as.data.frame(dist) dist_df[1:5, 1:5] ## V1 V2 V3 V4 V5 ## 1 338437.85 [m] 263692.1 [m] 377476.0 [m] 390771.33 [m] 362734.97 [m] ## 2 197203.45 [m] 122621.7 [m] 236789.3 [m] 249791.82 [m] 223192.16 [m] ## 3 381617.18 [m] 312604.5 [m] 413268.8 [m] 427894.89 [m] 393571.41 [m] ## 4 158689.76 [m] 139533.6 [m] 192053.6 [m] 196516.46 [m] 196519.69 [m] ## 5 88374.99 [m] 153727.1 [m] 50524.9 [m] 48850.39 [m] 52407.25 [m] colnames(dist_df) &lt;- fwy_sf_proj$UNIQUE_ID dist_df &lt;- dist_df %&gt;% mutate(Site = sites_sf_proj$Site) %&gt;% # add a column for Sites relocate(Site, .before = colnames(dist_df)[1]) # move to the front of the dataframe dist_df[1:5, 1:5] ## Site 12TVL21421309_I-80 EB_FWY 12TVK44214181_I-15 NB_FWY ## 1 1 338437.85 [m] 263692.1 [m] ## 2 2 197203.45 [m] 122621.7 [m] ## 3 3 381617.18 [m] 312604.5 [m] ## 4 4 158689.76 [m] 139533.6 [m] ## 5 5 88374.99 [m] 153727.1 [m] ## 12TVL528848324_I-84 WB_FWY 12TVL14996575_I-15 NB_FWY ## 1 377476.0 [m] 390771.33 [m] ## 2 236789.3 [m] 249791.82 [m] ## 3 413268.8 [m] 427894.89 [m] ## 4 192053.6 [m] 196516.46 [m] ## 5 50524.9 [m] 48850.39 [m] dist_df &lt;- dist_df %&gt;% pivot_longer(cols = -Site, names_to = &quot;Road_Name&quot;) head(dist_df) ## # A tibble: 6 x 3 ## Site Road_Name value ## &lt;int&gt; &lt;chr&gt; [m] ## 1 1 12TVL21421309_I-80 EB_FWY 338438. ## 2 1 12TVK44214181_I-15 NB_FWY 263692. ## 3 1 12TVL528848324_I-84 WB_FWY 377476. ## 4 1 12TVL14996575_I-15 NB_FWY 390771. ## 5 1 12TVL43954376_I-84 WB_FWY 362735. ## 6 1 12TVL22992231_I-15 NB_FWY 346788. dist_df &lt;- dist_df %&gt;% group_by(Site) %&gt;% mutate(Distance = min(value)) %&gt;% filter(value == Distance) %&gt;% dplyr::select(-value) head(dist_df) ## # A tibble: 6 x 3 ## # Groups: Site [6] ## Site Road_Name Distance ## &lt;int&gt; &lt;chr&gt; [m] ## 1 1 12SWH795644729_I-70 EB_FWY 111639. ## 2 2 12SVH54839499_I-70 WB_FWY 26694. ## 3 3 12SXJ29161112_I-70 EB_FWY 100145. ## 4 4 12SVJ06965812_I-15 SB_FWY 103257. ## 5 5 12TVL12119352_I-15 NB_FWY 41944. ## 6 6 12SVH54609503_I-70 EB_FWY 4126. We could then join this information to our Sites feature sites_sf_proj &lt;- left_join(sites_sf_proj, dist_df, by = &quot;Site&quot;) head(sites_sf_proj) ## Simple feature collection with 6 features and 4 fields ## Geometry type: POINT ## Dimension: XY ## Bounding box: xmin: 311534.1 ymin: 4188305 xmax: 656513.7 ymax: 4595255 ## Projected CRS: NAD83 / UTM zone 12N ## Site land_value Road_Name Distance ## 1 1 547 12SWH795644729_I-70 EB_FWY 111639.222 [m] ## 2 2 491 12SVH54839499_I-70 WB_FWY 26693.741 [m] ## 3 3 561 12SXJ29161112_I-70 EB_FWY 100145.037 [m] ## 4 4 498 12SVJ06965812_I-15 SB_FWY 103257.143 [m] ## 5 5 187 12TVL12119352_I-15 NB_FWY 41943.649 [m] ## 6 6 151 12SVH54609503_I-70 EB_FWY 4125.821 [m] ## geometry ## 1 POINT (516801.7 4188305) ## 2 POINT (470663.6 4322073) ## 3 POINT (656513.7 4212358) ## 4 POINT (311534.1 4398520) ## 5 POINT (454023.6 4595255) ## 6 POINT (455210.1 4289185) (Note that if you look at the help file i.e. ?st_distance, there are other functions to calculate geometric measurements for sf objects: st_area and st_length) 4.7 Raster Cell Stats In my research I often have to perform cell algebra or focal statistics. Maybe you need to know the average elevation or the total herbaceous biomass within a certain area. The way to get these values are with the function cellStats. We simply need to input the raster and the stat function: sum, mean, min, max, sd, or a homemade function. Lets say we need to calculate the average elevation, SWE, and snow depth within the buffer we made earlier. cellStats(stack_crop, stat = &quot;mean&quot;) ## elevation swe snow_depth ## 3281.0344 319.1429 1145.2181 Note that theres an option to include na.rm in the arguments. na.rm = TRUE is the default. 4.8 Calculate Terrain Characteristics From a DEM (digital elevation model) we can obtain a lot of other rasters that are likely useful in GIS research. The elevation raster weve been working with is a DEM. From a DEM we can derive other terrain characteristics : Slope: Measurement of steepness Aspect: Measurements of Northness and Eastness Flow direction of water: the direction of the greatest drop in elevation Terrain Ruggedness Index (TRI): the mean of the absolute differences between the value of a cell and the value of its 8 surrounding cells Topographic Position Index (TPI): the difference between the value of a cell and the mean value of its 8 surrounding cells Roughness: the difference between the maximum and the minimum value of a cell and its 8 surrounding cells These definitions came from the help file for the function we can use to derive these characteristics: terrain(). slope &lt;- terrain(elev_snow_stk$elevation, opt = &quot;slope&quot;, unit = &quot;radians&quot;) aspect &lt;- terrain(elev_snow_stk$elevation, opt = &quot;aspect&quot;, unit = &quot;radians&quot;) roughness &lt;- terrain(elev_snow_stk$elevation, opt = &quot;roughness&quot;) terrain_stk &lt;- stack(elev_snow_stk$elevation, slope, aspect, roughness) terrain_stk ## class : RasterStack ## dimensions : 7401, 5606, 41490006, 4 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 414639.5, 582819.5, 4428230, 4650260 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## names : elevation, slope, aspect, roughness ## min values : 1279.897, 0.000, 0.000, 0.000 ## max values : 4111.600098, 1.302171, 6.283185, 279.081787 To compute the Northness or Eastness of a cell, we actually have to do one more step to the aspect raster. Aspect is a circular measurement (which is why its units are in degrees or radians), so (if you remember how trigonometry works) to calculate northness and eastness we need to use cosine and sine respectively. Because our units are in radians, we can simply apply the cos() and sin() functions directly to the aspect raster. aspect_cos &lt;- cos(terrain_stk$aspect) aspect_sin &lt;- sin(terrain_stk$aspect) aspect_stk &lt;- stack(aspect_cos, aspect_sin) aspect_stk ## class : RasterStack ## dimensions : 7401, 5606, 41490006, 2 (nrow, ncol, ncell, nlayers) ## resolution : 30, 30 (x, y) ## extent : 414639.5, 582819.5, 4428230, 4650260 (xmin, xmax, ymin, ymax) ## crs : +proj=utm +zone=12 +datum=NAD83 +units=m +no_defs ## names : layer.1, layer.2 ## min values : -1, -1 ## max values : 1, 1 plot(aspect_stk) 4.9 A Note About Loops Learning all these functions is all well and good, but what if you have to perform them all on multiple features or rasters? Of course, you can always copy and paste, but that can soon become confusing and messy and cause your code to be inefficient. The better way to address this is with loops! for loops and lapply are lifesavers and I use them in all of my code. A previous workshop went into more depth on how to use loops, so I wont go over them in too much detail. But I do want to show some ways you can use them for GIS applications. (These code chunks are for demonstration only, these data and directories dont actually exist) # Example 1: Load a set of shapefiles and find the area for each filenames &lt;- list.files(dir) # get a list of shapefile names in a directory area_list &lt;- c() # create an empty vector for the areas to live in for(i in 1:length(filenames)){ # load the shapefile shp &lt;- st_read(filenames[i]) # calculate the area area &lt;- st_area(shp) # put the area into the vector area_list &lt;- c(area_list, area) } # -----------------------------------------------------------------------------X # Example 2: Load a set of shapefiles, generate a buffer for each, and calculate the # mean value of a raster within that buffer and the focal feature filenames &lt;- list.files(dir) # get a list of shapefile names in a directory r &lt;- raster(raster_filename) # load a raster lapply(filenames, function(fn){ # load a shapefile shp &lt;- st_read(fn) # generate a 10kmX10km buffer buffer &lt;- st_buffer(shp, dist = 10000) # crop the raster to the shape and the buffer r_shp &lt;- crop(r, extent(shp)) r_buffer &lt;- crop(r, extent(buffer)) # calculate the mean value of the raster within the buffer and the feature r_shp_mean &lt;- cellStats(r_shp, stat = &quot;mean&quot;, na.rm = TRUE) r_buff_mean &lt;- cellStats(r_shp, stat = &quot;mean&quot;, na.rm = TRUE) # return both means in a list return(list(r_shp_mean, r_buff_mean)) }) # -----------------------------------------------------------------------------X # Example 3: Generate a raster of the sum from a set of RasterStacks # and then save the output raster filenames &lt;- list.files(dir) # get a list of raster files in a directory out_names &lt;- paste0(filenames, &quot;_sum&quot;) lapply(1:length(filenames), function(i){ # load RasterStak stk &lt;- stack(filenames[i]) # create a raster that is the sum of all layers in the stack sum &lt;- calc(stk, fun = sum) sum &lt;- sum(stk) # these two operations are equivalent writeRaster(sum, out_names[i], format = &quot;GTiff&quot;) }) # -----------------------------------------------------------------------------X # Example 4: Pull the number of zeros in a set of rasters filenames &lt;- list.files(dir) # get a list of raster files in a directory lapply(filenames, function(fn){ # load raster rast &lt;- raster(fn) # get the number of zeros in the raster n_0 &lt;- getValues(rast) == 0 %&gt;% which() %&gt;% length() return(n_0) }) Even more efficient would be to run these in parallel, but that is way beyond the scope of this workshop I hope these functions helped you! The next chapter goes over some ways of obtaining the data we worked on today. "],["where-to-obtain-data-further-resources.html", "Chapter 5 Where to Obtain Data &amp; Further Resources 5.1 Data Sources 5.2 More Resources 5.3 Acknowledgements", " Chapter 5 Where to Obtain Data &amp; Further Resources 5.1 Data Sources 5.1.1 maps package There is package you can install called maps that contains a lot of global and national features (such as state boundaries, bodies of water, etc). These features dont contain a lot of data or attributes, so they are more useful for making maps and not so much for spatial analysis. However, Ive used them to pull state boundaries to get the extents I need for cropping rasters, for example. The help documentation for this package and this website show you how you can access different features from this package. Ill show you briefly how I use it to pull the state boundary of Utah: utah &lt;- maps::map(&quot;state&quot;, plot = F, fill = TRUE) %&gt;% # turn into sf obj sf::st_as_sf() %&gt;% # pull out utah dplyr::filter(ID == &quot;utah&quot;) utah ## Simple feature collection with 1 feature and 1 field ## Geometry type: MULTIPOLYGON ## Dimension: XY ## Bounding box: xmin: -114.0472 ymin: 36.99588 xmax: -109.0396 ymax: 42.00354 ## Geodetic CRS: WGS 84 ## ID geom ## 1 utah MULTIPOLYGON (((-114.0472 4... plot(st_geometry(utah)) 5.1.2 Utah GIS Many states and cities have GIS data that are publically available. To find them, typically I google something like Utah GIS data or the specific data Im looking for. Utah helpfully has a website called gis.utah.gov. Some data they have that could be useful for ecological research are Geoscience, Water, and Bioscience, just to name a few The highway feature and the management boundaries feature weve been working on in this workshop came from this website on their Transportation page and Land Ownership page respectively 5.1.3 Other Environmental Rasters In this workshop we worked with a DEM (digital elevation model) and snow data. In my own research I work with these data frequently. I also work with RAP (Rangeland Analysis Platform), which offers biomass and vegetation cover, and NDVI (Normalized Difference Vegetation Index), which reports an index of vegetation green-ness. Many of these rasters can be downloaded from the websites user-interface, but they can also be downloaded directly from R! This can be a bit complicated if youve never done it before, but fortunately Brian Smith, a PhD in WILD at USU, has already written a guide! My research is very temporally-dependent, and many of these rasters are available daily, weekly, or yearly. It can get very tedious to repeat lines and lines of code to download a years worth of daily rasters. This is, again, where loops come in handy! In this workshop we also worked with a Landcover/Landuse raster. I obtained that from here 5.2 More Resources This workshop really just touches the surface on how to work with GIS in R. There are a plethora of resources online to help you enhance what you learned today and help you solve your particular GIS problem. Here are just a few: https://cengel.github.io/R-spatial/ https://www.bookdown.org/mcwimberly/gdswr-book/ https://www.jessesadler.com/tags/gis/ https://geocompr.robinlovelace.net/ GIS stack exchange Google! 5.2.1 Learn more about GIS in general https://docs.qgis.org/3.22/en/docs/index.html https://wiki.gis.com/ https://gisgeography.com/ https://www.gislounge.com/ http://innovativegis.com/basis/primer/The_GIS_Primer_Buckley.pdf 5.3 Acknowledgements This workshop is partially adapted from Claudia Engel This website was created with R bookdown 5.3.1 Figure Citations Figure 2.4 Figure 2.5 Figure 2.6 Figure 2.13 "]]
